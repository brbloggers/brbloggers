+++
title = ""
date = "1-01-01"
categories = ["mind-and-iron"]
original_url = "http://ctlente.com/pt/teaching/ddr/"
+++

<body>
<textarea id="source">
class: center, middle, inverse, title-slide \# R DAY 2018: ESTRUTURAS DE
DADOS DISTRIBU√çDAS EM R \#\#\# Caio Lente \#\#\# 2018-05-22 ---
background-image:
url(<https://avatars2.githubusercontent.com/u/7017340?s=460&v=4>)
background-size: 38% background-position: 85% 20% \# Sobre Mim
&lt;br&gt;&lt;/br&gt; &lt;br&gt;&lt;/br&gt; &lt;br&gt;&lt;/br&gt;
&lt;br&gt;&lt;/br&gt; - Nome: Caio Truzzi Lente - Idade: Mais do que
parece - Cidade: S√£o Paulo, SP - Gradua√ß√£o: Ci√™ncia da Computa√ß√£o no
IME-USP - Est√°gio: Platipus + Associa√ß√£o Brasileira de Jurimetria -
Ensino: Curso-R + R6 --- \# √çndice O que veremos hoje: - Estruturas de
dados distribu√≠das - Motiva√ß√£o - Vis√£o geral - O pacote `ddR` -
Implementa√ß√£o - Vantagens e desvantagens - Trabalhos futuros - Rcpp e
companhia - ALTREP --- class: inverse, center, middle \# Estruturas de
Dados Distribu√≠das --- \# Uma Breve Introdu√ß√£o - Em torno dos anos 1980
o limite f√≠sico dos seus componentes passou a ser um motivo de
preocupa√ß√£o - Ser√° que podemos aumentar o clock para sempre? - A luz no
v√°cuo se propaga a aproximadamente 3x10&lt;sup&gt;8&lt;/sup&gt;m/s - A
mem√≥ria do seu computador est√° a apenas 5cm da CPU - O tempo de ida e
volta da mem√≥ria √© 1.7x10&lt;sup&gt;-10&lt;/sup&gt;s, limitando o clock
a no m√°ximo 6Ghz - Ao longo dos anos 1980 e 1990, passou-se a investir
pesadamente em tecnologias multithread e multicore - Cada n√∫cleo pode
processar mais de um fluxo de instru√ß√µes ao mesmo tempo e cada
processador pode ter mais de um n√∫cleo na sua placa -- - **Mas Caio,
como eu posso aproveitar essas novas tecnologias?** --- \# Um Mar De
Op√ß√µes - N√£o √© trivial fazer algoritmos e estruturas de dados tirarem
vantagem desse novo tipo de infraestrutura - Race conditions, deadlocks,
starvation e seus amigos s√£o o pavor de muitos alunos de gradua√ß√£o em
computa√ß√£o at√© os dias de hoje ü§¢ - Ascens√£o da nuvem: infraestrutura
baseada em clusters de computadores que conseguem se comunicar e dividir
tarefas entre si - Diversas bibliotecas tentam auxiliar o programador a
aproveitar todas essas tecnologias e abstrair um pouco da sua
complexidade: - Solu√ß√µes como `OpenMP` e `OpenACC` permitem a
paraleliza√ß√£o de c√≥digo com diretivas de compila√ß√£o - O `Spark` √© um
framework que facilita a distribui√ß√£o de conjuntos de dados ao longo de
clusters de computadores -- - **√â f√°cil usar essas tecnologias? Como eu
fa√ßo um data.frame em C++?** --- \# Voc√™ Quer Desempenho M√°ximo?
`c++ struct Sum : public Worker { const RVector&lt;double&gt; input; double value; Sum(const NumericVector input) : input(input), value(0) {} Sum(const Sum&amp; sum, Split) : input(sum.input), value(0) {} void operator()(std::size_t begin, std::size_t end) { value += std::accumulate(input.begin() + begin, input.begin() + end, 0.0); } void join(const Sum&amp; rhs) { value += rhs.value; } };`
-- - **D√° pra mudar de slide? Meus olhos est√£o doendo...** --- \# A
Linguagem R - Desde a sua concep√ß√£o o R foi desenvolvido para funcionar
com apenas uma thread - Ao longo do tempo foram aparecendo diversas
formas diferentes de trazer para o R as inova√ß√µes do processamento
paralelo - A Task View do CRAN sobre computa√ß√£o de alta performance
(HPC) tem um total de *noventa e seis* pacotes - O cen√°rio da HPC no R √©
fragmentado e pode n√£o trazer o benef√≠cio de performance que o usu√°rio
espera
`r #&gt; Unit: microseconds #&gt; expr min median max *#&gt; mcmapply(print, 1:10) 6049.376 8889.710 10234.454 #&gt; print(1:10) 188.723 343.851 757.422`
-- - **Caio, voc√™ j√° est√° no 8&lt;sup&gt;o&lt;/sup&gt; slide e n√£o teve
nenhum meme ainda!** --- \# O R No Seu Computador &lt;center&gt; &lt;img
src="static/tasks.png" width="401" /&gt; &lt;/center&gt; --- \#
Estruturas De Dados - A paraleliza√ß√£o de uma analise de dados quase
sempre envolver√° a paraleliza√ß√£o dos acessos a uma estrutura de dados
(ED) - Temos duas principais formas de paralelizar uma ED: - EDs
concorrentes residem em mem√≥ria compartilhada e podem ser acessadas por
mais de um thread ao mesmo tempo - Se pudermos distribuir essas EDs ao
longo de v√°rias m√°quinas, teremos uma ED distribu√≠da - Para tarefas
"padr√£o" de machine learning podemos usar o j√° citado `Spark`, que tem
uma implementa√ß√£o pr√≥pria de EDs distribu√≠das: Resilient Distributed
Datasets (RDDs) - A grande quest√£o √© que √© dif√≠cil programar seus
pr√≥prios algoritmos paralelos no `Spark`, acabamos dependendo do que j√°
est√° implementado -- - **C++ √© imposs√≠vel, Spark tem limita√ß√µes... Como
eu fa√ßo ent√£o?** --- class: inverse, center, middle \# O Pacote ddR ---
\# Os √Åtomos Do Pacote - A base do pacote s√£o justamente as estruturas
de dados; como discutido na se√ß√£o anterior, elas s√£o fundamentais para a
paraleliza√ß√£o - S√£o 3 diferentes tipos de EDs (`darray`, `dframe` e
`dlist`) e o `ddR` faz um bom trabalho de descrev√™-las para n√≥s
`r library(ddR) as.dlist(1:10000) #&gt; ddR Distributed Object #&gt; Type: dlist *#&gt; # of partitions: 10000 #&gt; Partitions per #&gt; dimension: 10000x1 #&gt; Partition sizes: [1], [1], [1], [1], [1], ... #&gt; Length: 10000 *#&gt; Backend: fork`
-- - **Ent√£o essas EDs s√£o concorrentes? Distribu√≠das? Os dois?** --- \#
Backends - O `ddR` funciona com backends, permitindo que um mesmo c√≥digo
possa ser interpretado de forma concorrente ou distribu√≠da - Por padr√£o
o backend √© o `fork`, mas com uma s√≥ linha podemos usar o `parallel` ou
o `distributedR`
`r useBackend(&quot;parallel&quot;) as.dlist(1:10000) #&gt; ddR Distributed Object #&gt; Type: dlist #&gt; # of partitions: 10000 #&gt; Partitions per #&gt; dimension: 10000x1 #&gt; Partition sizes: [1], [1], [1], [1], [1], ... #&gt; Length: 10000 *#&gt; Backend: parallel`
-- - **Ok, Caio, muito bonito. Mas o que eu fa√ßo com isso?** --- \# Um
Exemplo - A grande sacada do `ddR` √© permitir que fun√ß√µes sejam
aplicadas aos objetos atrav√©s de uma *primitiva funcional* chamada
`dmapply()` - A interface dessa fun√ß√£o √© igual ao `mapply()` mas ela tem
completa integra√ß√£o com os backends, permitindo com que a aplica√ß√£o seja
concorrente ou distribu√≠da
`r library(ddR) f &lt;- function(x) { length(runif(x)) } microbenchmark::microbenchmark( base = mapply(f, 1:10000), ddR = dmapply(f, 1:10000)) #&gt; Unit: milliseconds #&gt; expr min median max #&gt; base 1402.0951 1429.4116 1467.857 *#&gt; ddR 701.6403 721.4495 778.761`
-- - **Isso √© magia negra? Quero ver um outro exemplo!** --- \# Outro
Exemplo
`r *means &lt;- dmapply(mean, as.dlist(data.frame(1:4, 5:8, 9:12))) means # ddR Distributed Object # Type: dlist # # of partitions: 3 # Partitions per # dimension: 3x1 # Partition sizes: [1], [1], [1] # Length: 3 # Backend: parallel collect(means) # $X1.4 # [1] 2.5 # # $X5.8 # [1] 6.5 # # $X9.12 # [1] 10.5`
--- \# Controle De Threds? - A maior parte dos nossos problemas s√£o
vergonhosamente paraleliz√°veis, ent√£o podemos abrir m√£o do controle dos
threads &lt;img src="static/dogs.jpeg" width="1143" /&gt; -- - **Os
cachorros s√£o fofos, mas isso √© tudo que o ddR faz?** --- \# Algoritmos
Embutidos - O `ddR` j√° vem com alguns algoritmos pr√©-prontos para que
voc√™ possa tirar vantagem das suas abstra√ß√µes em alto n√≠vel
`r library(randomForest); library(randomForest.ddR) microbenchmark::microbenchmark( rf = randomForest(medv ~ ., MASS::Boston), dfr = drandomForest(medv ~ ., MASS::Boston, nExecutor = 4)) #&gt; Unit: milliseconds #&gt; expr min median max #&gt; rf 594.8163 621.4649 899.2687 *#&gt; drf 291.7429 309.5159 584.8597`
- O `ddR` n√£o √© o framework mais veloz do mercado e n√£o permite que o
programador tenha controle fino sobre os threads de execu√ß√£o... - *Mas*
o que ele nos permite √© ganhar muito desempenho sem ter que mudar nada
da sintaxe que j√° conhecemos -- - **S√≥ acredito vendo... Sem nenhum
gr√°fico voc√™ n√£o me convence.** --- \# Benchmarks - Random Forest,
K-Means e Regress√£o &lt;img src="static/rf.png" width="374" /&gt;
&lt;img src="static/kmeans.png" width="367" /&gt; &lt;center&gt; &lt;img
src="static/reg.png" width="366" /&gt; &lt;/center&gt; --- class:
inverse, center, middle \# Trabalhos Futuros --- \# Novos Algoritmos - O
`ddR` j√° tem um punhado de algoritmos pr√©-prontos: `randomForest.ddR`,
`pagerank.ddR`, `kmeans.ddR` e `glm.ddR` - No meu trabalho de conclus√£o
de curso, me propus a implementar mais dois algoritmos: `prcomp.ddR` e
`gam.ddR` - O primeiro destes est√° j√° foi implementado e est√° sendo
otimizado - Para paralelizar o algoritmo da PCA, √© necess√°rio fazer uma
estima√ß√£o da matriz de vari√¢ncia-covari√¢ncia a partir de c√°lculos
realizados separadamente nas parti√ß√µes horizontais da tabela
&lt;center&gt; &lt;img src="static/pca.png" width="584" /&gt;
&lt;/center&gt; -- - **Isso tudo √© bem legal, mas e se eu quiser *mais*
desempenho?** --- \# C++ - Os desenvolvedores originais do pacote
fizeram toda a sua infraestrutura em R, o que pode reduzir a performance
da biblioteca - Usando ferramentas como o `Rcpp`, o `RcppParallel` e o
`RcppArmadillo` √© poss√≠vel otimizar o comportamento das fun√ß√µes do
`ddR`, diminuindo o overhead de uma s√©rie de opera√ß√µes
`r microbenchmark::microbenchmark( otimizado = as_darray(matriz_1000_50, c(1, 50)), original = as.darray(matriz_1000_50, c(1, 50))) #&gt; Unit: microseconds #&gt; expr min median max neval #&gt; otimizado 513.973 953.1695 8477.453 100 *#&gt; original 204338.956 242818.3535 1492324.670 100`
- No exemplo acima vemos que o processo de distribui√ß√£o otimizado chega
a ser ~250 vezes mais r√°pido do que o original -- - **Existe alguma
forma de isso tudo ser feito automaticamente pelo R?** --- \# ALTREP -
`ALTREP` √© um branch do do R que fornece um framework para o
desenvolvimento de representa√ß√µes alternativas para objetos do R - Isso
permite, por exemplo, o c√°lculo instant√¢neo da mediana de um vetor que
tenha sido previamente ordenado - A `ALTVEC` (representa√ß√£o alternativa
de vetores) j√° passou a ser suportada no R 3.5 lan√ßado em 23/04/2018 -
Se este framework come√ßar a ser adotado no R padr√£o, ser√° poss√≠vel criar
representa√ß√µes alternativas que por padr√£o j√° sejam distribu√≠das -
Teremos uma abstra√ß√£o completamente transparente ao usu√°rio que poder√°,
por tr√°s dos panos, otimizar computa√ß√µes que sejam identificadas como
vergonhosamente paralelas -- - **Mas isso √© uma conversa para outra
hora...** --- class: inverse, center, middle \# Obrigado
<ctlente@curso-r.com> ddr.ctlente.com github.com/ctlente
</textarea>
</body>

