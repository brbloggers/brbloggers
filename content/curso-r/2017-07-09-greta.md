+++
title = "Greta"
date = "2017-07-08 07:12:00"
categories = ["curso-r"]
original_url = "http://curso-r.com/blog/2017/07/08/2017-07-09-greta/"
+++

<p class="text-muted text-uppercase mb-small text-right">
Por <a href="http://curso-r.com/author/daniel">Daniel</a> 08/07/2017
</p>
<p>
Estou bem longe de ter experiência em modelagem bayesiana usando
linguagens de programação probabilística como Stan ou BUGS, mas vi esse
pacote chamado
<a href="https://goldingn.github.io/greta/get_started.html"><code>greta</code></a>
que me chamou a atenção.
</p>
<p>
O <code>greta</code> é um pacote feito totalmente em R, mas que usa o
TensorFlow como backend para fazer os seus cálculos. Isso tudo por
intermédio do <code>reticulate</code>. A vantagem de usar o TensorFlow
como <em>backend</em> é a escalabilidade: o <code>greta</code> pode ser
rápido até mesmo em bases de dados grandes e também pode ser acelerada
usando clusters de CPU’s ou GPU’s.
</p>
<p>
O <code>greta</code> já está disponível no CRAN e pode ser instalado
com:
</p>
<pre class="r"><code>install.packages(&quot;greta&quot;)</code></pre>
<p>
Vou mostrar um exemplo simples copiado da página de início do site do
próprio <code>greta</code> e depois vou implementar um modelo que o
Fernando implementou aqui no blog em um outro post sobre estimar um
modelo heterocedástico no R.
</p>
<p>
Vamos implementar o modelo de regressão linear mais simples possível.
Temos duas variáveis contínuas <span class="math inline">*x*</span> e
<span class="math inline">*y*</span> e queremos estimar um modelo da
forma:
</p>
<p>
<span class="math display">
*y* = *a* + *b* \* *x* + *ϵ*
</span>
</p>
<p>
em que <span class="math inline">*ϵ*</span> possui distribuição normal
com média zero e desvio padrão <span class="math inline">*σ*</span>. No
greta isso pode ser feito da seguinte forma:
</p>
<pre class="r"><code>library(greta)
# define as vari&#xE1;veis x e y
x &lt;- iris$Petal.Length
y &lt;- iris$Sepal.Length # define a distribui&#xE7;&#xE3;o priori dos par&#xE2;metros
a = normal(0, 5)
b = normal(0, 3)
sd = lognormal(0, 3) # define o modelo
mean &lt;- a + b * x
distribution(y) = normal(mean, sd)
m &lt;- model(a, b, sd) # retira amostras usando mcmc
draws &lt;- mcmc(m, n_samples = 1000)</code></pre>
<p>
Você pode fazer um gráfico para visualizar as estimativas dos parâmetros
usando o <code>bayesplot</code>:
</p>
<pre class="r"><code>bayesplot::mcmc_trace(draws, facet_args = list(ncol = 1))</code></pre>
<img src="http://curso-r.com/img/greta/Rplot.png" alt="">

<p>
Podemos obter as estimativas pontuais dos parâmetros pegando, por
exemplo, a mediana dessa amostra do MCMC.
</p>
<pre class="r"><code>apply(draws[[1]], 2, median)
## a b sd ## 4.2805710 0.4219092 0.3697692</code></pre>
<p>
Esse resultado é muito similar ao que pode ser obtido por uma regressão
linear simples:
</p>
<pre class="r"><code>lm(y ~ x)
## ## Call:
## lm(formula = y ~ x)
## ## Coefficients:
## (Intercept) x ## 4.3066 0.4089</code></pre>

<p>
<a href="http://curso-r.com/blog/2017/03/09/2017-02-21-regressao-heterocedastica/">Neste
post</a> o Fernando simulou um banco de dados que é heterocedástico e
depois ajustou um modelo deste tipo de diversas maneiras, vou
acrescentar mais uma aqui, desta vez usando o <code>greta</code>.
</p>
<p>
Vou simular o banco de dados da mesma forma que o Fernando:
</p>
<pre class="r"><code>library(ggplot2) N &lt;- 1000 set.seed(11071995)
X &lt;- sample((N/100):(N*3), N)
Y &lt;- rnorm(N,X,4*sqrt(X)) qplot(X,Y) + theme_bw(15) + geom_point(color = &apos;darkorange&apos;) </code></pre>
<p>
<img src="http://curso-r.com/blog/2017-07-09-greta_files/figure-html/unnamed-chunk-6-1.png" width="672">
</p>
<pre class="r"><code>
X2 &lt;- sqrt(X)
dataset &lt;- data.frame(Y,X,X2)</code></pre>
<p>
Agora o código em <code>greta</code> para ajustar esse modelo:
</p>
<pre class="r"><code># definir os vetores
y &lt;- dataset$Y
x &lt;- dataset$X
x2 &lt;- dataset$X2 # definir prioris dos par&#xE2;metros
alpha &lt;- gamma(1, 1)
beta &lt;- normal(0, 10) # definir liga&#xE7;&#xF5;es
mean &lt;- beta * x
sd &lt;- alpha * x2 # definir o modelo
distribution(y) = normal(mean, sd)
m &lt;- model(alpha, beta) # ajustar
draws &lt;- mcmc(m, n_samples = 1000)</code></pre>
<p>
Agora as estimativas pontuais:
</p>
<pre class="r"><code>apply(draws[[1]], 2, median)
## alpha beta ## 4.077689 1.002791</code></pre>
<p>
Como esperado, chegamos em estimativas bem próximas do que foi simulado.
</p>
<p>
Por hoje é isso!! Abraços!
</p>

