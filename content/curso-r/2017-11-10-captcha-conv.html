<div><p>Voltando aos saudosos captchas. Demorei para fazer esse post pois estava esperando o lan&#xE7;amento do <a href="https://www.coursera.org/learn/convolutional-neural-networks">curso de redes neurais convolucionais do Andrew Ng</a>. O curso foi muito bom, valeu &#xE0; pena! E, como prometido, vamos agora trabalhar com modelagem dos captchas.</p><div id="objetivo" class="section level2"> <p>Nosso objetivo &#xE9; aprender a aplicar a <strong>opera&#xE7;&#xE3;o da convolu&#xE7;&#xE3;o</strong> em imagens, replicando o modelo j&#xE1; ajustado dos captchas. O jeito que fazemos para ajustar o modelo ficar&#xE1; para um pr&#xF3;ximo post.</p>
<div id="pre-requisitos" class="section level3"> <p>Na nossa jornada, utilizaremos o pacote <code>decryptr</code> e utilizaremos como o base o captcha da Receita Federal. Para baixar um captcha e plotar na sua tela, rode o gr&#xE1;fico abaixo. Utilizaremos o caminho do arquivo em <code>arq</code> v&#xE1;rias vezes no decorrer do post. Instale tamb&#xE9;m o pacote <code>decryptrModels</code> para carregar o modelo ajustado do captcha da receita.</p>
<pre class="r"><code># devtools::install_github(&quot;decryptr/decryptr&quot;)
# devtools::install_github(&quot;decryptr/decryptrModels&quot;)
library(decryptr)
arq &lt;- captcha_download_rfb(dest = &quot;img&quot;)
arq %&gt;% read_captcha() %&gt;% plot()</code></pre>
<p><img src="http://curso-r.com/blog/2017-11-10-captcha-conv_files/figure-html/unnamed-chunk-2-1.png" width="288"></p>
<p>Tamb&#xE9;m precisaremos de conhecimentos do pacote <a href="https://keras.rstudio.com/"><code>keras</code></a>, um pacote maravilhoso feito pela turma do <a href="https://rstudio.com/">RStudio</a>, com contribui&#xE7;&#xF5;es do <a href="http://curso-r.com/author/daniel/">Daniel Falbel</a>. N&#xE3;o esque&#xE7;a de fazer o <code>tensorflow</code> funcionar na sua m&#xE1;quina! <a href="http://curso-r.com/blog/2017/06/08/2017-06-08-keras-no-ubuntu/">Esse post</a> do <a href="http://curso-r.com/author/athos/">Athos Damiani</a> pode ajudar.</p>
<pre class="r"><code># install.packages(&quot;keras&quot;)
library(keras)</code></pre>
<p>Para os retoques finais, vamos usar o pacote <code>magick</code> para fazer algumas brincadeiras com as imagens. Meu intuito inicial era usar a fun&#xE7;&#xE3;o <code>image_convolve()</code> desse pacote, mas infelizmente essa opera&#xE7;&#xE3;o &#xE9; limitada. Ent&#xE3;o acabei usando apenas fun&#xE7;&#xF5;es para juntar imagens e fazer gifs. Se quiser mais detalhes sobre o <code>magick</code>, veja o excelente post <a href="http://curso-r.com/blog/2017/06/01/2017-06-01-a-kind-of-magick/">A kind of magick</a>, feito pelo <a href="http://curso-r.com/author/william/">William Amorim</a>.</p>
<pre class="r"><code># install.packages(&quot;magick&quot;)
library(magick)
## Linking to ImageMagick 6.7.7.10
## Enabled features: cairo, fontconfig, freetype, fftw, lcms, pango, rsvg, x11
## Disabled features: ghostscript, webp</code></pre>
</div>
</div><div id="o-que-e-convolucao-afinal" class="section level2"> <p><img src="http://curso-r.com/blog/img/vivalaconv.jpg" width="50%"></p>
<p>Convolu&#xE7;&#xE3;o &#xE9; uma t&#xE9;cnica usada h&#xE1; muito tempo na &#xE1;rea de <em>vis&#xE3;o computacional</em> para aplicar filtros em imagens e detec&#xE7;&#xE3;o de padr&#xF5;es. Basicamente, o que ela faz &#xE9; obter um novo valor para um pixel da imagem com base nos pixels da vizinhan&#xE7;a. Por exemplo, voc&#xEA; pode fazer com que o pixel <span class="math inline">\((i,j)\)</span> da sua imagem seja atualizado pela soma ponderada dos valores dos pixels na vizinhan&#xE7;a.</p>
<blockquote>
<p>Se voc&#xEA; n&#xE3;o est&#xE1; entendendo nada, Veja o v&#xED;deo abaixo para entender o que s&#xE3;o pixels. No nosso caso, teremos uma matriz com valores entre zero e um, sendo zero = preto e um = branco.</p>
</blockquote>
<iframe width="400" height="225" src="https://www.youtube.com/embed/m8c1CAT2zEI" class="">
</iframe>
<p>Uma forma esperta de fazer essa m&#xE9;dia ponderada considerando os pixels da vizinhan&#xE7;a &#xE9; criando uma matriz de pesos: dessa forma, voc&#xEA; n&#xE3;o precisa ficar procurando os pontos. Para cada ponto <span class="math inline">\((i,j)\)</span>, voc&#xEA; pega o subset da matriz de vizinhan&#xE7;a, multiplica pontualmente pela matriz de pesos e soma todos os valores. E isso &#xE9; <em>exatamente</em> o que a convolu&#xE7;&#xE3;o faz.</p>
<p>Daqui em diante, chamaremos essa matriz de pesos de <strong>kernel</strong>. Considere esse exemplo 3x3:</p>
<pre class="r"><code>kern_horizontal &lt;- rbind(c(-1,-1,-1), c( 0, 0, 0), c( 1, 1, 1))
kern_horizontal
## [,1] [,2] [,3]
## [1,] -1 -1 -1
## [2,] 0 0 0
## [3,] 1 1 1</code></pre>
<p>E considere essa imagem super complexa:</p>
<p><img src="http://curso-r.com/blog/2017-11-10-captcha-conv_files/figure-html/unnamed-chunk-7-1.png" width="30%"></p>
<p>Na pr&#xE1;tica, essa imagem &#xE9; isso aqui (tirei algumas colunas):</p>
<pre class="r"><code>emoji &lt;- load_image(&quot;img/emoji3.png&quot;)[,,1] round(emoji, 1)[1:10, 1:12]
## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]
## [1,] 1 1 1 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0
## [2,] 1 1 1 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0
## [3,] 1 1 1 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0
## [4,] 1 1 1 1.0 1.0 1.0 1.0 1.0 0.8 0.7 0.7 0.7
## [5,] 1 1 1 1.0 1.0 1.0 0.9 0.6 0.8 1.0 1.0 1.0
## [6,] 1 1 1 1.0 1.0 0.8 0.7 1.0 1.0 1.0 1.0 1.0
## [7,] 1 1 1 1.0 0.9 0.7 1.0 1.0 1.0 1.0 1.0 1.0
## [8,] 1 1 1 1.0 0.6 1.0 1.0 1.0 1.0 1.0 1.0 1.0
## [9,] 1 1 1 0.8 0.8 1.0 1.0 0.9 0.9 1.0 1.0 1.0
## [10,] 1 1 1 0.7 1.0 1.0 0.7 0.4 0.2 0.7 0.9 1.0</code></pre>
<p>Tome por exemplo o ponto <span class="math inline">\((i,j) = (12,16)\)</span>. A vizinhan&#xE7;a 3x3 em torno desse ponto &#xE9; dada por</p>
<pre class="r"><code>emoji[12 + (-1):1, 16 + (-1):1]
## [,1] [,2] [,3]
## [1,] 0.9843137 0.5294118 0.7921569
## [2,] 0.9725490 0.9882353 1.0000000
## [3,] 0.9843137 1.0000000 0.9960784</code></pre>
<p>A opera&#xE7;&#xE3;o de convolu&#xE7;&#xE3;o &#xE9; feita da seguinte forma:</p>
<pre class="r"><code>sum(emoji[12 + (-1):1, 16 + (-1):1] * kern_horizontal)
## [1] 0.6745098</code></pre>
<p>Pronto, esse &#xE9; o valor a ser colocado no ponto <span class="math inline">\((i,j)\)</span>. Fazemos isso para todos os outros pontos. Algumas d&#xFA;vidas que podem rolar nesse ponto:</p>
<p><strong>Q</strong>: Mas os n&#xFA;meros n&#xE3;o devem variar de 0 a 1?</p>
<p><strong>R</strong>: N&#xE3;o! Para visualizar a imagem, voc&#xEA; pode normalizar essas quantidades (por exemplo, dividindo pelo m&#xE1;ximo). Mas quem disse que o resultado da sua opera&#xE7;&#xE3;o precisa ser visualiz&#xE1;vel? O resultado pode at&#xE9; ser negativo. Para visualiza&#xE7;&#xE3;o, por padr&#xE3;o os valores menores que zero s&#xE3;o substitu&#xED;dos por zero (preto) e valores maiores que um s&#xE3;o substitu&#xED;dos por um (branco). Sem problemas.</p>
<p><strong>Q</strong>: Mas e no canto da imagem, o que fazemos?</p>
<p><strong>R</strong>: Nos cantos, voc&#xEA; tem duas op&#xE7;&#xF5;es: 1) considerar apenas os pixels <em>v&#xE1;lidos</em>, ou seja, pixels em que voc&#xEA; consegue encaixar a matriz <code>kernel</code> inteira, resultando numa matriz de tamanho menor; ou 2) criar uma borda na imagem, preenchendo com zeros, para que toda a imagem fique com pixels v&#xE1;lidos.</p>
<p><strong>Q</strong>: E se a imagem for colorida?</p>
<p><strong>R</strong>: Boa pergunta, Julio! Se a imagem for colorida, voc&#xEA; pode considerar um <code>kernel</code> diferente para cada cor. Mais pra frente, chamaremos as cores de <em>canais</em>, pois teremos muito mais do que 3 kernels.</p>
<p>Com base nisso, juntei a conta num algoritmo que faz a conta para todos os pixels, j&#xE1; criando uma borda na imagem:</p>
<pre class="r"><code>convolve &lt;- function(img, kern) { # monta a bordinha na imagem. A borda deve ter (tamanho kernel) / 2, # de tamanho, arredondando para baixo pad &lt;- floor(dim(kern)[1] / 2) img_pad &lt;- matrix(0, nrow = nrow(img) + 2 * pad, ncol = ncol(img) + 2 * pad) img_pad[pad + 1:nrow(img), pad + 1:ncol(img)] &lt;- img[,,1] # aplica a convolu&#xE7;&#xE3;o nos pontos da imagem for (i in seq_len(nrow(img))) { for (j in seq_len(ncol(img))) { img[i, j, 1] &lt;- sum(img_pad[i + 0:(2 * pad), j + 0:(2 * pad)] * kern) } } img[,,2] &lt;- img[,,3] &lt;- img[,,1] img
}</code></pre>
<p>(desculpe aos amigos por usar <code>for</code>. Shame on me&#x2026;)</p>
<p>No nosso caso, o resultado fica assim:</p>
<pre class="r"><code>&quot;img/emoji3.png&quot; %&gt;% load_image() %&gt;% convolve(kern_horizontal) %&gt;% image_read() %&gt;% plot()</code></pre>
<p><img src="http://curso-r.com/blog/2017-11-10-captcha-conv_files/figure-html/unnamed-chunk-12-1.png" width="30%"></p>
<p>Ficou um pouco assustador, n&#xE3;o? Essa matriz n&#xE3;o foi escolhida por acaso. Ela serve para destacar padr&#xF5;es horizontais da imagem. Como a primeira linha &#xE9; formada <code>-1</code>s e a &#xFA;ltima &#xE9; formada por <code>1</code>s, a matriz fica com valor alto se a parte de cima do pixel for preta e a parte de baixo for branca (<code>grande * 1 + pequeno * (-1)</code>). A parte destacada da imagem acabou sendo os olhos (pois temos maior concentra&#xE7;&#xE3;o de pixels pretos ali), al&#xE9;m das extremidades superior e inferior do</p>
<p>Com esse kernel aqui (vertical), a parte destacada do rosto s&#xE3;o as extremidades dos lados:</p>
<pre class="r"><code>kern_vertical &lt;- rbind(c(-1, 0, 1), c(-1, 0, 1), c(-1, 0, 1))
kern_vertical
## [,1] [,2] [,3]
## [1,] -1 0 1
## [2,] -1 0 1
## [3,] -1 0 1 &quot;img/emoji3.png&quot; %&gt;% load_image() %&gt;% convolve(kern_vertical) %&gt;% image_read() %&gt;% plot()</code></pre>
<p><img src="http://curso-r.com/blog/2017-11-10-captcha-conv_files/figure-html/unnamed-chunk-13-1.png" width="30%"></p> </div><div id="aplicando-nos-captchas" class="section level2"> <p>Para aplicar nos captchas, n&#xE3;o tem segredo. Vou apenas introduzir uma nova fun&#xE7;&#xE3;o chamada <code>add_bias()</code>, que simplesmente adiciona uma constante num&#xE9;rica para a matriz. Isso pode auxiliar na visualiza&#xE7;&#xE3;o, pois controlamos melhor os valores que ficam dentro do intervalo <code>[0,1]</code>. L&#xE1; na frente voc&#xEA; entender&#xE1; o porqu&#xEA; do &#x201C;bias&#x201D;.</p>
<pre class="r"><code>add_bias &lt;- function (x, b) x + b</code></pre>
<p>Esse &#xE9; o resultado de adicionar o kernel vertical e bias de <code>0.8</code>.</p>
<pre class="r"><code>arq %&gt;% load_image() %&gt;% convolve(kern_vertical) %&gt;% add_bias(.8) %&gt;% image_read() %&gt;% plot()</code></pre>
<p><img src="http://curso-r.com/blog/2017-11-10-captcha-conv_files/figure-html/unnamed-chunk-15-1.png" width="345.6"></p>
<p>Agora na horizontal. Note os padr&#xF5;es das linhas horizontais que tentam atrapalhar a identifica&#xE7;&#xE3;o das letras.</p>
<pre class="r"><code>arq %&gt;% load_image() %&gt;% convolve(kern_horizontal) %&gt;% add_bias(.8) %&gt;% image_read() %&gt;% plot()</code></pre>
<p><img src="http://curso-r.com/blog/2017-11-10-captcha-conv_files/figure-html/unnamed-chunk-16-1.png" width="345.6"></p>
<p>Colocando um ap&#xF3;s o outro, temos um resultado bem esquisito:</p>
<pre class="r"><code>arq %&gt;% load_image() %&gt;% convolve(kern_horizontal) %&gt;% convolve(kern_vertical) %&gt;% add_bias(.7) %&gt;% image_read() %&gt;% plot()</code></pre>
<p><img src="http://curso-r.com/blog/2017-11-10-captcha-conv_files/figure-html/unnamed-chunk-17-1.png" width="345.6"></p>
<p>Tamb&#xE9;m vou introduzir uma fun&#xE7;&#xE3;o chamada <code>relu()</code> aqui. <strong>ReLu</strong> significa <em>Restricted Linear Unit</em> e &#xE9; uma fun&#xE7;&#xE3;o bem simples que zera tudo aquilo que &#xE9; negativo e mant&#xE9;m tudo aquilo que &#xE9; positivo. Assim,</p>
<pre class="r"><code>relu &lt;- function(x) (x + abs(x)) / 2
relu(-1)
## [1] 0
relu( 3)
## [1] 3</code></pre>
<p>Para visualiza&#xE7;&#xE3;o, essa fun&#xE7;&#xE3;o n&#xE3;o serve para muita coisa, pois j&#xE1; fazemos a substitui&#xE7;&#xE3;o de valores negativos por zero na pr&#xE1;tica. No entanto, podemos fazer combos com a aplica&#xE7;&#xE3;o de v&#xE1;rias convolu&#xE7;&#xF5;es, que n&#xE3;o seriam poss&#xED;veis somente com somas e multiplica&#xE7;&#xF5;es. Na pr&#xE1;tica, estou dizendo que podemos aplicar opera&#xE7;&#xF5;es <strong>n&#xE3;o lineares</strong> para extrair componentes da imagem.</p>
<p>Olhe o exemplo abaixo. Parece que consegui identificar bem coisas que s&#xE3;o in&#xFA;teis na imagem. Isso pode ser &#xFA;til&#x2026; ou n&#xE3;o.</p>
<pre class="r"><code>par(mar=c(.1,.1,.1,.1))
arq %&gt;% load_image() %&gt;% # primeira convolucao convolve(kern_horizontal) %&gt;% add_bias(-.25) %&gt;% relu() %&gt;% # segunda convolucao convolve(kern_vertical) %&gt;% add_bias(.1) %&gt;% image_read() %&gt;% plot()</code></pre>
<p><img src="http://curso-r.com/blog/2017-11-10-captcha-conv_files/figure-html/unnamed-chunk-19-1.png" width="345.6"></p>
<p>Isso nos leva a pensar: ser&#xE1; que eu consigo pensar em kernels que me ajudem a identificar as letras de uma forma razo&#xE1;vel?</p> </div><div id="e-se-pudermos-usar-kernels-treinados" class="section level2"> <p>A revolu&#xE7;&#xE3;o da convolu&#xE7;&#xE3;o aparece quando conseguimos obter kernels &#xFA;teis por m&#xE9;todos estat&#xED;sticos. Podemos pensar na matriz abaixo</p>
<p><span class="math display">\[
W = \left[\begin{array}{ccccc}
w_{11} &amp; w_{12} &amp; w_{13} &amp; w_{14} &amp; w_{15} \\
w_{21} &amp; w_{22} &amp; w_{23} &amp; w_{24} &amp; w_{25} \\
w_{31} &amp; w_{32} &amp; w_{33} &amp; w_{34} &amp; w_{35} \\
w_{41} &amp; w_{42} &amp; w_{43} &amp; w_{44} &amp; w_{45} \\
w_{51} &amp; w_{52} &amp; w_{53} &amp; w_{54} &amp; w_{55}
\end{array}\right]
\]</span></p>
<p>E tentar encontrar os valores de <span class="math inline">\(W\)</span> que minimizem alguma fun&#xE7;&#xE3;o de interesse. Podemos pensar que esses s&#xE3;o os <span class="math inline">\(\beta\)</span>&#x2019;s de uma regress&#xE3;o log&#xED;stica, e queremos encontrar os valores que minimizam a minha <em>Loss</em> ou maximizam a minha <em>verossimilhan&#xE7;a</em>. Para ver mais sobre isso, recomendo o excelente post do Athos sobre <a href="http://curso-r.com/blog/2017/07/29/2017-07-29-segundo-menor-dl/">a menor deep learning do mundo</a>. N&#xF3;s tamb&#xE9;m podemos fazer v&#xE1;rios <span class="math inline">\(W\)</span> como esse, sendo que cada um extrai alguma coisa de importante da imagem.</p>
<p>Nosso super modelo de magia negra nada mais &#xE9; do que isso: a aplica&#xE7;&#xE3;o consecutiva de <code>convolve()</code>, <code>add_bias()</code> e <code>relu()</code>, mas com pesos escolhidos a dedo (ou por um moedor de carne super-avan&#xE7;ado como o <code>keras</code>).</p>
<p>Agora podemos ver nosso modelo atual da Receita Federal:</p>
<pre class="r"><code>m &lt;- decryptrModels::read_model(&quot;rfb&quot;)
m$model</code></pre>
<pre><code>Model
____________________________________________________________________________________________________
Layer (type) Output Shape Param # ====================================================================================================
conv2d_4 (Conv2D) (None, 50, 180, 12) 312 ____________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D) (None, 25, 90, 12) 0 ____________________________________________________________________________________________________
conv2d_5 (Conv2D) (None, 25, 90, 48) 14448 ____________________________________________________________________________________________________
max_pooling2d_5 (MaxPooling2D) (None, 12, 45, 48) 0 ____________________________________________________________________________________________________
conv2d_6 (Conv2D) (None, 12, 45, 96) 115296 ____________________________________________________________________________________________________
max_pooling2d_6 (MaxPooling2D) (None, 6, 22, 96) 0 ____________________________________________________________________________________________________
flatten_2 (Flatten) (None, 12672) 0 ____________________________________________________________________________________________________
dense_3 (Dense) (None, 32) 405536 ____________________________________________________________________________________________________
dropout_2 (Dropout) (None, 32) 0 ____________________________________________________________________________________________________
dense_4 (Dense) (None, 210) 6930 ____________________________________________________________________________________________________
reshape_2 (Reshape) (None, 6, 35) 0 ____________________________________________________________________________________________________
activation_2 (Activation) (None, 6, 35) 0 ====================================================================================================
Total params: 542,522
Trainable params: 542,522
Non-trainable params: 0
____________________________________________________________________________________________________</code></pre>
<p>Nosso modelo aplica convolu&#xE7;&#xE3;o 3 vezes consecutivas e faz algumas coisas que n&#xE3;o entendemos. Explico agora:</p>
<ol>
<li><code>conv2d_</code>: s&#xE3;o as convolu&#xE7;&#xF5;es. As aplica&#xE7;&#xF5;es de <code>add_bias()</code> e <code>relu()</code> est&#xE3;o escondidas a&#xED; dentro.</li>
<li><code>max_pooling2d_</code>: serve para simplificar a imagem. Isso ajuda a fazer computa&#xE7;&#xF5;es mais r&#xE1;pido e ajuda a pegar mais rela&#xE7;&#xF5;es entre partes da imagem, sem precisar mudar o tamanho dos kernels.</li>
<li><code>dropout_</code>: &#xE9; utilizado para regulariza&#xE7;&#xE3;o. Ou seja, serve para evitar que seu modelo quebre apenas o captcha que voc&#xEA; tem na base, e n&#xE3;o novos captchas que chegam. Na pr&#xE1;tica, o <em>dropout</em> joga fora uma parte dos <span class="math inline">\(W\)</span> obtidos. Se voc&#xEA; consegue prever coisas bem sem esses <span class="math inline">\(W\)</span>, isso significa que eles n&#xE3;o s&#xE3;o t&#xE3;o &#xFA;teis assim.</li>
<li><code>flatten_</code> e <code>reshape_</code>: n&#xE3;o fazem nada: s&#xF3; reorganizam os par&#xE2;metros de matriz para vetor e vetor para matriz. Isso &#xE9; &#xFA;til pois i) depois de aplicar os kernels, n&#xF3;s misturamos todos os par&#xE2;metros resultantes e ii) no final, precisamos prever 6 letras, ent&#xE3;o precisamos deixar as probabilidades numa matriz, <a href="http://curso-r.com/blog/2017/07/31/2017-06-29-captcha-dados/">como vimos no post anterior sobre captchas</a>.</li>
<li><code>dense_</code>: s&#xE3;o camadas de redes neurais igual como as do <a href="http://curso-r.com/blog/2017/07/29/2017-07-29-segundo-menor-dl/">post do Athos</a>.</li>
</ol>
<p><strong>N&#xC3;O ME ABANDONE AQUI!!!</strong> Se voc&#xEA; n&#xE3;o estiver entendendo direito, saiba apenas que a execu&#xE7;&#xE3;o de um modelo de deep learning envolve somente</p>
<ol>
<li>Pegar o input</li>
<li>Multiplicar por alguns pesos <span class="math inline">\(W\)</span>.</li>
<li>Adicionar um vi&#xE9;s (ou bias, ou intercepto) <span class="math inline">\(b\)</span>.</li>
<li>Aplicar uma fun&#xE7;&#xE3;o n&#xE3;o linear, por exemplo ReLu.</li>
<li>Voltar para 2 v&#xE1;rias vezes (o deep vem da&#xED;).</li>
<li>Pegar os pesos finais e normalizar (usando, por exemplo, <em>softmax</em>) para obter probabilidades dos resultados.</li>
</ol>
<p>No nosso caso, repetimos o passo 2 tr&#xEA;s vezes, aplicando tr&#xEA;s convolu&#xE7;&#xF5;es seguidas.</p>
<div id="primeira-convolucao" class="section level3"> <p>Para obter os valores de kernels ajustados pelo modelo, podemos usar a fun&#xE7;&#xE3;o <code>get_weights()</code> do <code>keras</code>. Nessa primeira parte, utilizamos 12 kernels 5x5.</p>
<pre class="r"><code>w &lt;- keras::get_weights(m$model$layers[[1]])[[1]]
w_list &lt;- purrr::map(seq_len(dim(w)[4]), ~w[,,1,.x])
bias &lt;- keras::get_weights(m$model$layers[[1]])[[2]]
w_list[[1]]</code></pre>
<pre><code> [,1] [,2] [,3] [,4] [,5]
[1,] -0.00889198 0.04569587 0.11906113 0.08591988 -0.09028889
[2,] -0.05898214 0.20692091 -0.13479255 -0.15641896 -0.10511240
[3,] 0.02517573 -0.63352644 -3.81658459 -4.39883375 -1.05918467
[4,] -0.22003661 -1.80763698 -3.13373542 -1.73096466 -0.01640752
[5,] -0.02915078 -0.11879896 -0.07475707 0.06014036 0.15733875</code></pre>
<p>Os doze valores de <code>bias</code> estimados pelo modelo (um para cada matriz) s&#xE3;o dados por</p>
<pre class="r"><code>round(bias, 3)</code></pre>
<pre><code>[1] 0.150 0.013 0.181 -0.275 0.179 0.040 -0.128 -0.036 0.030 0.042 0.201 0.043</code></pre>
<p>Para cada matriz dessas doze, temos uma matriz convolu&#xED;da. Essas matrizes s&#xE3;o os resultados que a matriz entende serem &#xFA;teis para prever o captcha.</p>
<p>O c&#xF3;digo abaixo aplica <code>convolve()</code>, <code>add_bias()</code> e <code>relu()</code> em todos os . Se voc&#xEA; n&#xE3;o entende <code>purrr</code>, leia <a href="http://ctlente.com/pt/purrr-magic/">este excelente post do Caio Lente</a>.</p>
<pre class="r"><code>conv1 &lt;- purrr::map2(w_list, bias, ~{ arq %&gt;% load_image() %&gt;% convolve(.x) %&gt;% add_bias(.y) %&gt;% relu()
})</code></pre>
<p>Como ser&#xE1; que ficam essas imagens? Abaixo, temos o resultado da aplica&#xE7;&#xE3;o dos doze kernels. A maioria dos kernels parece estar extraindo partes da imagem. O s&#xE9;timo (posi&#xE7;&#xE3;o <code>(2,3)</code> da imagem abaixo) parece estar pegando o ru&#xED;do e o quarto parece guardar a imagem original.</p>
<p><img src="http://curso-r.com/blog/2017-11-10-captcha-conv_files/figure-html/unnamed-chunk-24-1.png" width="864"></p>
<p>O gif animado abaixo mostra a aplica&#xE7;&#xE3;o do oitavo kernel da nossa lista. Com esse kernel d&#xE1; pra pegar bem o padr&#xE3;o das letras, n&#xE3;o &#xE9;?</p>
<div class="figure">
<img src="http://curso-r.com/blog/img/captcha_conv.gif" alt=""> </div>
<p>No pr&#xF3;ximo n&#xED;vel, vamos convoluir mais 48 kernels. Essa opera&#xE7;&#xE3;o ser&#xE1; feita com todos os doze filtros atuais, ou seja, &#xE9; uma contaiada que n&#xE3;o acaba mais. Para simplificar as contas e para permitir a obten&#xE7;&#xE3;o de padr&#xF5;es diferentes, faz sentido simplificar a imagem. Para isso, usamos o <em>max pooling</em></p>
<div id="fazendo-max-pooling" class="section level4"> <p>O max pooling nada mais faz do que pegar o pixel de maior valor dentro de uma janela. No caso, estamos usando uma janela 2x2 e aplicamos ela igualzinho convolu&#xE7;&#xE3;o, s&#xF3; que ao inv&#xE9;s de pegar a soma ponderada dos pixels, pegamos o pixel m&#xE1;ximo. Outra diferen&#xE7;a &#xE9; que ao inv&#xE9;s de andar o pixel de 1 em 1, andamos de 2 em 2. Assim cada janelinha &#xE9; considerada apenas uma vez (esse &#xE9; o conceito de <em>strides</em>, que n&#xE3;o vou discutir aqui).</p>
<p>O algoritmo que faz max pooling &#xE9; esse aqui:</p>
<pre class="r"><code>max_pool &lt;- function(img) { # monta a matriz com metade da resolu&#xE7;&#xE3;o x_new &lt;- matrix(0.0, nrow = floor(nrow(img) / 2), ncol = floor(ncol(img) / 2)) # adiciona uma bordinha para o caso da matriz ter um n&#xFA;mero &#xED;mpar de pixels # por exemplo, se ela &#xE9; 51x181, daria bug se n&#xE3;o adicionar a bordinha img &lt;- cbind(rbind(img[,,1], 0), 0) # percorre a matrix pegando o m&#xE1;ximo das janelinhas for (i in 1:nrow(x_new)) { for (j in 1:ncol(x_new)) { x_new[i, j] &lt;- max(img[i * 2 - 1 + 0:1, j * 2 - 1 + 0:1]) } } array(x_new, c(dim(x_new), 3))
}</code></pre>
<p>A aplica&#xE7;&#xE3;o da primeira convolu&#xE7;&#xE3;o com max pooling &#xE9; feita igual anteriormente:</p>
<pre class="r"><code>result_conv1 &lt;- purrr::map2(w_list, bias, ~{ arq %&gt;% load_image() %&gt;% convolve(.x) %&gt;% add_bias(.y) %&gt;% relu() %&gt;% max_pool()
})</code></pre>
<p>No final, temos essas imagens com resolu&#xE7;&#xE3;o 25x90 (as originais s&#xE3;o 50x180).</p>
<p><img src="http://curso-r.com/blog/2017-11-10-captcha-conv_files/figure-html/unnamed-chunk-27-1.png" width="864"></p>
<p>Ficou bem parecido com o anterior!</p>
<p>Ao final da convolu&#xE7;&#xE3;o, &#xE9; como se tiv&#xE9;ssemos uma nova imagem, menor e alterada, mas com 12 cores. Como n&#xE3;o faz muito sentido pensar em 12 cores prim&#xE1;rias, vamos cham&#xE1;-las de canais.</p> </div>
</div>
<div id="segunda-convolucao" class="section level3"> <p>Os par&#xE2;metros da segunda convolu&#xE7;&#xE3;o s&#xE3;o obtidos novamente pelo <code>keras</code>. Sugiro que voc&#xEA; d&#xEA; uma olhada nesses &#xED;ndices para entender o que exatamente estamos pegando.</p>
<pre class="r"><code>w2 &lt;- keras::get_weights(m$model$layers[[3]])[[1]]
bias2 &lt;- keras::get_weights(m$model$layers[[3]])[[2]] dim(w2)</code></pre>
<pre><code>[1] 5 5 12 48</code></pre>
<p>Agora temos <code>12 * 48</code> kernels 5x5 a serem aplicados. Precisamos:</p>
<ol>
<li>Para cada uma das 48 matrizes:
<ol>
<li>Fa&#xE7;a a convolu&#xE7;&#xE3;o das 12 matrizes obtidos na convolu&#xE7;&#xE3;o anterior pelos 12 kernels atuais e <strong>some</strong> os valores obtidos.</li>
<li>Adicione o bias.</li>
<li>Fa&#xE7;a a ativa&#xE7;&#xE3;o com ReLu.</li>
<li>Aplique o max pooling.</li>
</ol></li>
</ol>
<p>Logo, temos 2 la&#xE7;os. O c&#xF3;digo para fazer isso fica assim:</p>
<pre class="r"><code>result_conv2 &lt;- purrr::map(1:dim(w2)[4], ~{ kern &lt;- w2[,,,.x] %&gt;% plyr::alply(3, identity) %&gt;% purrr::map(as.matrix) actual_bias &lt;- bias2[[.x]] purrr::map2(result_conv1, kern, convolve) %&gt;% purrr::reduce(magrittr::add) %&gt;% add_bias(actual_bias) %&gt;% relu() %&gt;% max_pool()
})</code></pre>
<p>Plotamos os 48 resultados abaixo. Alguns resultados foram completamente zerados (eles devem ser &#xFA;teis em outros captchas mais esquisitos), enquanto os demais pegam peda&#xE7;os da imagem anterior que mal lembram o captcha original. A imagem da posi&#xE7;&#xE3;o <code>(4,1)</code> &#xE9; uma das &#xFA;nicas que mostra o captcha claramente. Isso mostra uma coisa comum do deep learning: quanto mais profundo vamos, menos entendemos o que de fato o modelo est&#xE1; fazendo. Recomendo fortemente a leitura <a href="https://distill.pub/2017/feature-visualization/">desse blog</a>, que discute o assunto de forma extensiva.</p>
<p><img src="http://curso-r.com/blog/2017-11-10-captcha-conv_files/figure-html/unnamed-chunk-30-1.png" width="864"></p>
<p>Agora temos 48 canais de uma imagem com dimens&#xF5;es 12x45. Vamos em frente.</p>
</div>
<div id="terceira-convolucao" class="section level3"> <p>A terceira convolu&#xE7;&#xE3;o &#xE9; feita de forma id&#xEA;ntica &#xE0; segunda. A &#xFA;nica diferen&#xE7;a &#xE9; que teremos no final 96 canais, pois estamos ajustando essa quantidade de kernels para cada canal.</p>
<pre class="r"><code>w3 &lt;- keras::get_weights(m$model$layers[[5]])[[1]]
bias3 &lt;- keras::get_weights(m$model$layers[[5]])[[2]] dim(w3)</code></pre>
<pre><code>[1] 5 5 48 96</code></pre>
<p>Revisando o algoritmo:</p>
<pre class="r"><code>result_conv3 &lt;- purrr::map(1:dim(w3)[4], ~{ kern &lt;- w3[,,,.x] %&gt;% plyr::alply(3, identity) %&gt;% purrr::map(as.matrix) actual_bias &lt;- bias3[[.x]] purrr::map2(result_conv2, kern, convolve) %&gt;% purrr::reduce(magrittr::add) %&gt;% add_bias(actual_bias) %&gt;% relu() %&gt;% max_pool()
})</code></pre>
<p>Plotando os resultados, temos</p>
<p><img src="http://curso-r.com/blog/2017-11-10-captcha-conv_files/figure-html/unnamed-chunk-33-1.png" width="864"></p>
<p>No final, ficamos com 96 imagens com resolu&#xE7;&#xE3;o 6x22 cada. V&#xE1;rias imagens ficaram zeradas e as que n&#xE3;o ficaram parecem apenas feixes de luz no meio do breu total. Pode ser que a posi&#xE7;&#xE3;o dessas luzes tenha a ver com a posi&#xE7;&#xE3;o de peda&#xE7;os importantes do captcha original, que podem ajudar a prever o valor do captcha.</p>
<div id="verificando-se-funcionou-mesmo" class="section level4"> <p>Quando eu montei o post, n&#xE3;o estava 100% seguro das contas que estava fazendo. Pode ser que tenha alguma coisa diferente feita dentro do <code>keras</code>, que &#xE9; um canh&#xE3;o que usa <code>tensorflow</code> por tr&#xE1;s, fazendo alguma otimiza&#xE7;&#xE3;o esquisita. Por isso, tamb&#xE9;m aprendi a plotar os resultados parciais do modelo quebrador de captchas diretamente do <code>keras</code>.</p>
<p>Podemos montar um modelo <em>parcial</em> do <code>keras</code> escolhendo qual o <em>layer</em> final do modelo.</p>
<pre class="r"><code>m2 &lt;- keras::keras_model( inputs = m$model$input, outputs = keras::get_layer(m$model, &quot;max_pooling2d_6&quot;)$output
)
m2</code></pre>
<pre><code>Model
____________________________________________________________________________________________________
Layer (type) Output Shape Param # ====================================================================================================
conv2d_4_input (InputLayer) (None, 50, 180, 1) 0 ____________________________________________________________________________________________________
conv2d_4 (Conv2D) (None, 50, 180, 12) 312 ____________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D) (None, 25, 90, 12) 0 ____________________________________________________________________________________________________
conv2d_5 (Conv2D) (None, 25, 90, 48) 14448 ____________________________________________________________________________________________________
max_pooling2d_5 (MaxPooling2D) (None, 12, 45, 48) 0 ____________________________________________________________________________________________________
conv2d_6 (Conv2D) (None, 12, 45, 96) 115296 ____________________________________________________________________________________________________
max_pooling2d_6 (MaxPooling2D) (None, 6, 22, 96) 0 ====================================================================================================
Total params: 130,056
Trainable params: 130,056
Non-trainable params: 0
____________________________________________________________________________________________________</code></pre>
<p>Esse modelo &#xE9; id&#xEA;ntico ao inicial, mas acaba no &#xFA;ltimo max pooling. Para obter as imagens, utilizamos a fun&#xE7;&#xE3;o <code>predict</code> a partir da base de dados <code>X</code> montada a partir do <code>arq</code>, utilizando a fun&#xE7;&#xE3;o <code>prepare</code> do <code>decryptr</code>:</p>
<pre class="r"><code>X &lt;- prepare(read_captcha(arq))$x
res &lt;- predict(m2, X) dim(res)</code></pre>
<pre><code>[1] 1 6 22 96</code></pre>
<p>O resultado pode ser plotado da seguinte forma:</p>
<pre class="r"><code>par(mfrow = c(12, 8), mar = c(.1,.1,.1,.1))
purrr::walk(seq_len(dim(res)[4]), ~{ array(res[,,,.x], c(dim(res)[2:3], 3)) %&gt;% image_read() %&gt;% plot()
})</code></pre>
<p><img src="http://curso-r.com/blog/2017-11-10-captcha-conv_files/figure-html/unnamed-chunk-36-1.png" width="864"></p>
<p>Ufa, igualzinho!!! Apenas um final check: quero ver se os pesos obtidos s&#xE3;o todos iguais. Para isso, ordeno todos os pesos obtidos diretamente pelo <code>keras</code> ou aplicando as minhas fun&#xE7;&#xF5;es feitas no bra&#xE7;o:</p>
<pre class="r"><code>w_calculado &lt;- unlist(purrr::map(result_conv3, ~.x[,,1]))
all.equal(sort(res), sort(w_calculado), tolerance = 1e-6)</code></pre>
<pre><code>[1] TRUE</code></pre>
<p>UHUL!</p>
</div>
<div id="visualizando-na-imagem-original" class="section level4"> <p>Aqui fiz um esfor&#xE7;o para tentar entender que parte da imagem original esses resultados est&#xE3;o pegando informa&#xE7;&#xF5;es. Para isso, re-escalei essas imagens de resolu&#xE7;&#xE3;o mais baixa na &#xFA;ltima convolu&#xE7;&#xE3;o para o tamanho original da imagem (50x180) e depois multipliquei os valores das matrizes pelos valores da imagem original.</p>
<p>O resultado foi esse gif. Cada imagem &#xE9; um dos canais obtidos.</p>
<div class="figure">
<img src="http://curso-r.com/blog/img/captcha_conv_final.gif" alt=""> </div>
<p>Parece que os filtros s&#xE3;o capazes de pegar as curvas que as letras fazem no captcha. Mas n&#xE3;o tenho opini&#xE3;o formada sobre isso. Digam a&#xED; nos coment&#xE1;rios o que voc&#xEA;s acham!</p>
</div>
</div>
</div><div id="passos-finais" class="section level2"> <p>Para acabar a predi&#xE7;&#xE3;o do captcha, n&#xF3;s pegamos os resultados das imagens anteriores e juntamos todos os pixels num vetorz&#xE3;o com tudo junto. Esse vetor nada mais &#xE9; do que uma linha de um <code>data.frame</code>, que podemos usar numa regress&#xE3;o log&#xED;stica, por exemplo. Ou seja, essas convolucionais funcionam como um grande gerador autom&#xE1;tico de features importantes para prever os resultados do captcha. A vantagem &#xE9; que essas features s&#xE3;o obtidas de forma autom&#xE1;tica e s&#xE3;o otimizadas dentro do processo de estima&#xE7;&#xE3;o. Deep learning &#xE9; realmente sensacional!</p>
<p>Como j&#xE1; estamos no framework do <code>keras</code>, fazemos tudo l&#xE1; dentro. Ap&#xF3;s jogar tudo num vetorz&#xE3;o, aplicamos mais dois layers de redes neurais comuns, que funcionam como a regress&#xE3;o log&#xED;stica. O &#xFA;nico detalhe sens&#xED;vel &#xE9; que, como estamos prevendo 6 letras ao mesmo tempo, precisamos novamente transformar esse vetor em uma matriz <code>35x6</code>, sendo <code>35</code> o total de letras poss&#xED;veis por posi&#xE7;&#xE3;o e <code>6</code> a quantidade de posi&#xE7;&#xF5;es.</p>
<pre class="r"><code>res2 &lt;- keras::predict_proba(m$model, X)
probabilidades &lt;- res2[1,,] %&gt;% tibble::as_tibble() %&gt;% purrr::set_names(m$labs) %&gt;% tidyr::gather(letra, prob) %&gt;% dplyr::group_by(letra) %&gt;% dplyr::mutate(pos = 1:n()) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate(prob = dplyr::if_else(prob &lt; 5e-5, &quot;.&quot;, as.character(round(prob, 6))) ) %&gt;% tidyr::spread(pos, prob, sep = &quot;&quot;)</code></pre>
<pre class="r"><code>knitr::kable(probabilidades)</code></pre>
<table>
<thead> </thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="even">
<td>2</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="odd">
<td>3</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="even">
<td>4</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="odd">
<td>5</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>0.999999</td>
<td>.</td>
</tr>
<tr class="even">
<td>6</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="odd">
<td>7</td>
<td>.</td>
<td>.</td>
<td>0.999987</td>
<td>.</td>
<td>.</td>
<td>0.000317</td>
</tr>
<tr class="even">
<td>8</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="odd">
<td>9</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="even">
<td>a</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="odd">
<td>b</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="even">
<td>c</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="odd">
<td>d</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="even">
<td>e</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="odd">
<td>f</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="even">
<td>g</td>
<td>.</td>
<td>0.999949</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>0.001286</td>
</tr>
<tr class="odd">
<td>h</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="even">
<td>i</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="odd">
<td>j</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="even">
<td>k</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="odd">
<td>l</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="even">
<td>m</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="odd">
<td>n</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="even">
<td>o</td>
<td>0.999887</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="odd">
<td>p</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="even">
<td>q</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>0.998395</td>
</tr>
<tr class="odd">
<td>r</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="even">
<td>s</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="odd">
<td>t</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="even">
<td>u</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="odd">
<td>v</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>0.999997</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="even">
<td>w</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="odd">
<td>x</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="even">
<td>y</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="odd">
<td>z</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
</tbody>
</table>
<p>Ficamos ent&#xE3;o com &#x201C;o&#x201D; na primeira posi&#xE7;&#xE3;o, &#x201C;g&#x201D; na segunda posi&#xE7;&#xE3;o, &#x201C;7&#x201D; na terceira posi&#xE7;&#xE3;o, &#x201C;v&#x201D; na quarta posi&#xE7;&#xE3;o, &#x201C;5&#x201D; na quinta posi&#xE7;&#xE3;o e &#x201C;q&#x201D; na sexta posi&#xE7;&#xE3;o. Ou seja, &#x201C;og7v5q&#x201D;.</p>
<p>Vamos ver a imagem novamente:</p>
<pre class="r"><code>arq %&gt;% read_captcha() %&gt;% plot()</code></pre>
<p><img src="http://curso-r.com/blog/2017-11-10-captcha-conv_files/figure-html/unnamed-chunk-41-1.png" width="672"></p>
<p>Correto!</p>
</div><div id="wrap-up" class="section level2"> <p>Nossa jornada foi longa, mas acho que aprendemos bastante coisa. Resumindo:</p>
<ul>
<li>Convolu&#xE7;&#xF5;es s&#xE3;o somas ponderadas dos valores de pixels na vizinhan&#xE7;a do pixel. Esses pesos s&#xE3;o dados por uma matriz chamada kernel.</li>
<li>Aplicar redes neurais convolucionais consiste em i) aplicar convolu&#xE7;&#xE3;o; ii) adicionar um bias; iii) aplicar uma fun&#xE7;&#xE3;o n&#xE3;o linear (geralmente ReLu).</li>
<li>max pooling serve para simplificar</li>
<li>Na pr&#xE1;tica, aplicamos v&#xE1;rios kernels. O n&#xFA;mero de kernels de uma convolucional est&#xE1; relacionado com o n&#xFA;mero de cores da imagem e, de forma mais gen&#xE9;rica, com o n&#xFA;mero de canais que ela tem. Podemos tamb&#xE9;m escolher quantos canais queremos calcular.</li>
<li>No nosso caso, aplicamos tr&#xEA;s convolucionais com kernels 5x5, sendo <code>12</code> no primeiro n&#xED;vel, <code>12*48</code> no segundo n&#xED;vel e <code>48*96</code> no terceiro n&#xED;vel.</li>
<li>Depois, pegamos as imagens resultantes e aplicamos o <code>flatten</code>, para trabalhar com esses n&#xFA;meros como se fossem a matriz <code>X</code> em um estudo de regress&#xE3;o log&#xED;stica usual.</li>
<li>&#xC9; poss&#xED;vel implementar os algoritmos na m&#xE3;o sem dar muito trabalho.</li>
</ul>
<p>Mas como &#xE9; que, de fato, conseguimos esses valores de <span class="math inline">\(W\)</span> m&#xE1;gicos? Na pr&#xF3;xima vez provavelmente falarei da parte mais te&#xF3;rica do problema, mostrando como se faz o back-propagation em um modelo de deep learning.</p>
<p>&#xC9; isso. Happy coding :)</p>
</div></div>
