<div><p class="text-muted text-uppercase mb-small text-right"> Por <a href="http://curso-r.com/author/athos">Athos</a> , <a href="http://curso-r.com/author/julio">Julio</a> 22/05/2018 </p><div id="post-content"> <p>Modelos baseados em &#xE1;rvores como &#xE1;rvores de decis&#xE3;o, random forest, ligthGBM e xgboost s&#xE3;o conhecidos, dentre outras qualidades, pela sua robust&#xEA;s diante do problema de multicolinearidade. &#xC9; sabido que seu poder preditivo n&#xE3;o se abala na presen&#xE7;a de vari&#xE1;veis extremamente correlacionadas.</p>
<p>Por&#xE9;m, quem nunca usou um Random Forest pra fazer sele&#xE7;&#xE3;o de vari&#xE1;veis? Pegar, por exemplo, as top 10 mais importantes e descartar o resto?</p>
<p>Ou at&#xE9; mesmo arriscou uma interpreta&#xE7;&#xE3;o e concluiu sobre a ordem das vari&#xE1;veis mais importantes?</p>
<p>Abaixo mostraremos o porqu&#xEA; n&#xE3;o devemos ignorar a quest&#xE3;o da multicolinearidade completamente!</p>
<div id="um-modelo-bonitinho" class="section level2"> <p>Primeiro vamos ajustar um modelo bonitinho, livre de multicolinearidade. Suponha que queiramos prever <code>Petal.Length</code> utilizando as medidas das s&#xE9;palas (<code>Sepal.Width</code> e <code>Sepal.Length</code>) da nossa boa e velha base <code>iris</code>.</p>
<pre class="r"><code>library(tidyverse)
## &#x2500;&#x2500; Attaching packages &#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500; tidyverse 1.2.1 &#x2500;&#x2500;
## &#x2714; ggplot2 2.2.1.9000 &#x2714; purrr 0.2.4 ## &#x2714; tibble 1.4.2 &#x2714; dplyr 0.7.4 ## &#x2714; tidyr 0.8.0 &#x2714; stringr 1.3.1 ## &#x2714; readr 1.1.1 &#x2714; forcats 0.3.0
## &#x2500;&#x2500; Conflicts &#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500; tidyverse_conflicts() &#x2500;&#x2500;
## &#x2716; dplyr::filter() masks stats::filter()
## &#x2716; dplyr::lag() masks stats::lag()
## &#x2716; dplyr::vars() masks ggplot2::vars() iris2 &lt;- iris %&gt;% select(Sepal.Length, Sepal.Width, Petal.Length)
iris2 %&gt;% cor %&gt;% corrplot::corrplot()</code></pre>
<p><img src="http://curso-r.com/blog/2018-05-22-arvore-e-multicolinearidade_files/figure-html/unnamed-chunk-2-1.png" width="672"></p>
<p>O gr&#xE1;fico acima mostra que as vari&#xE1;veis explicativas n&#xE3;o s&#xE3;o fortemente correlacionadas. Ajustando uma random fores, temos a seguinte ordem de import&#xE2;ncia das vari&#xE1;veis:</p>
<pre class="r"><code>library(randomForest)
iris2_rf &lt;- randomForest(Petal.Length ~ ., data = iris2)
varImpPlot(iris2_rf)</code></pre>
<p><img src="http://curso-r.com/blog/2018-05-22-arvore-e-multicolinearidade_files/figure-html/unnamed-chunk-3-1.png" width="672"></p>
<p>Sem surpresas. Agora vamos para o problema!</p>
</div> <div id="selecao-de-variaveis-furado" class="section level2"> <p>O gr&#xE1;fico abaixo mostra que quanto mais vari&#xE1;veis correlacionadas tivermos, menor a import&#xE2;ncia de TODAS ELAS SIMULTANEAMENTE! &#xC9; como se as vari&#xE1;veis colineares repartissem a import&#xE2;ncia entre elas.</p>
<pre class="r"><code># ajusta random forest para bases com 1 a 20 repeti&#xE7;&#xF5;es de `Sepal.Length`
rfs &lt;- map(iris3, ~ randomForest(Petal.Length ~ ., data = .x) %&gt;% importance) # extrai as import&#xE2;ncias das repeti&#xE7;&#xF5;es de `Sepal.Length`
importancia &lt;- map_dfr(rfs, ~{ .x %&gt;% as.data.frame() %&gt;% tibble::rownames_to_column() %&gt;% dplyr::filter(stringr::str_detect(rowname, &quot;^Sepal.Length&quot;))
}, .id = &quot;n_repeticoes&quot;) %&gt;% mutate(n_repeticoes = as.numeric(n_repeticoes)) # Gr&#xE1;fico do n&#xFA;mero de vari&#xE1;veis multicolineares vs import&#xE2;ncia
importancia %&gt;% ggplot(aes(x = n_repeticoes, y = IncNodePurity)) + geom_point() + geom_hline(yintercept = 40, size = 1, linetype = &quot;dashed&quot;, colour = &quot;red&quot;) + labs(x = &quot;Qtd de repeti&#xE7;&#xF5;es da coluna `Sepal.Length`&quot;, y = &quot;Import&#xE2;ncia&quot;, title = &quot;Gr&#xE1;fico da rela&#xE7;&#xE3;o entre o n&#xFA;mero de vari&#xE1;veis multicolineares vs import&#xE2;ncia&quot;)</code></pre>
<p><img src="http://curso-r.com/blog/2018-05-22-arvore-e-multicolinearidade_files/figure-html/unnamed-chunk-6-1.png" width="672"></p>
<p>Na pr&#xE1;tica, se estabelecessemos um corte no valor de import&#xE2;ncia pra descartar vari&#xE1;veis (como ilustrado pela linha vermelha), ter&#xED;amos um problema em potencial: poder&#xED;amos estar jogando fora informa&#xE7;&#xE3;o muito importante.</p>
</div> <div id="conclusao" class="section level2"> <p>Cuidado ao jogar tudo no caldeir&#xE3;o! Devemos sempre nos preocupar com multicolinearidade, mesmo ajustando modelos baseados em &#xE1;rvores.</p>
<p>Abs!</p>
</div> </div></div>
